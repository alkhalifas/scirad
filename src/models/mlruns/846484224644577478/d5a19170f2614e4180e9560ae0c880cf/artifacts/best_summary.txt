The first article explores the application of reinforcement learning (RL) in group social dilemmas, specifically within the context of public goods games. It highlights the challenges of RL in complex environments where multiple agents learn simultaneously, leading to unpredictable and suboptimal outcomes. The study focuses on the tragedy of the commons and free-rider effects in AI cooperation, bridging traditional and evolutionary game theory by examining agents with intermediate intelligence. The research investigates how learning parameters and evolutionary pressures influence cooperation levels and exploration rates, using simulations and differential equations. The findings reveal conditions that favor different exploration levels and enhance the understanding of combining evolutionary algorithms with Q-learning, contributing to the evolution of machine behavior in social dilemmas.

The second article addresses the challenge of data sparsity in sequential recommendation models by proposing a multi-agent reinforcement learning framework for cross-domain sequential recommendation (MARL4CDSR). This framework leverages user interaction data across multiple domains to improve recommendations in data-sparse target domains. Unlike traditional methods, MARL4CDSR employs agents to selectively transfer relevant items from source domains, optimizing the transfer process through coordinated strategies. An information fusion module with a cross-attention mechanism aligns source and target domain item representations. The framework's effectiveness is demonstrated on Amazon domains, showing significant improvements in recommendation metrics, particularly in sparse target domains like the Movies&Booksâ†’Toys task, where it enhances NDCG@10 and HR@10 by 14.76% and 10.25%, respectively. Both articles contribute to advancing the application of multi-agent reinforcement learning in complex, cooperative, and data-sparse environments.