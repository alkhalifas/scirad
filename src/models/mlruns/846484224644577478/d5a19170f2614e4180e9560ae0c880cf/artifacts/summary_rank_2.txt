The first article explores the application of evolutionary multi-agent reinforcement learning (RL) in the context of group social dilemmas, specifically focusing on Q-learning in public goods games. The study addresses the challenges posed by complex learning environments, where the simultaneous learning of multiple agents can lead to unpredictable and suboptimal outcomes. By analyzing artificial intelligence cooperation within this framework, the research investigates traditional and evolutionary game theory's intersection with multi-agent RL, especially concerning the tragedy of the commons and free-rider effects. The researchers examine how learning parameters influence cooperation and how evolutionary pressures affect exploration rates, identifying conditions that separate strategies in specific game classes. The work contributes to the understanding of combining evolutionary algorithms with Q-learning, furthering insights into machine behavior evolution in social dilemmas.

The second article proposes a multi-agent reinforcement learning framework for cross-domain sequential recommendation (MARL4CDSR) to tackle data sparsity in sequential recommendation models. The traditional approaches, which focus on transferring information from the entire source domain sequence, often lead to misalignment between user interests in target and source domains. By employing agents to selectively transfer relevant items from source domain sequences, MARL4CDSR optimizes the transfer process, leveraging a multi-agent RL framework and a cross-attention mechanism for embedding alignment. The method is evaluated across three Amazon domains, demonstrating superior performance over baselines. Notably, it significantly improves NDCG@10 and HR@10 metrics in sparse interaction sequences, showcasing enhanced recommendation capabilities through strategic and collaborative knowledge transfer across domains.